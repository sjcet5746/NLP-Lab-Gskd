{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79352f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'sit' given the condition ('Can', 'I'):1.0\n",
      "Probability of 'near' given the condition ('I', 'sit'):1.0\n",
      "Probability of 'you' given the condition ('sit', 'near'):1.0\n",
      "Probability of 'You' given the condition ('near', 'you'):1.0\n",
      "Probability of 'can' given the condition ('you', 'You'):1.0\n",
      "Probability of 'sit' given the condition ('You', 'can'):1.0\n",
      "Probability of 'Sit' given the condition ('can', 'sit'):1.0\n",
      "Probability of 'near' given the condition ('sit', 'Sit'):1.0\n",
      "Probability of 'him' given the condition ('Sit', 'near'):1.0\n",
      "Probability of 'I' given the condition ('near', 'him'):1.0\n",
      "Probability of 'can' given the condition ('him', 'I'):1.0\n",
      "Probability of 'sit' given the condition ('I', 'can'):1.0\n",
      "Probability of 'sit' given the condition ('I', 'can'):1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import trigrams\n",
    "from nltk.probability import ConditionalFreqDist, ConditionalProbDist, MLEProbDist\n",
    "corpus = [\n",
    " \"Can I sit near you\",\n",
    " \"You can sit\",\n",
    " \"Sit near him\",\n",
    " \"I can sit you\"\n",
    "]\n",
    "tokenized_corpus = [nltk.word_tokenize(sentence) for sentence in corpus]\n",
    "trigram_list = list(trigrams(word for sentence in tokenized_corpus for word in sentence))\n",
    "cfd = ConditionalFreqDist()\n",
    "for trigram in trigram_list:\n",
    "    condition = (trigram[0], trigram[1])\n",
    "    cfd[condition][trigram[2]] += 1\n",
    "    cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
    "    trigram_probabilities = {}\n",
    "    for condition in cpd.conditions():\n",
    "        trigram_probabilities[condition] = {}\n",
    "    for word in cpd[condition].samples():\n",
    "        trigram_probabilities[condition][word] = cpd[condition].prob(word)\n",
    "        for condition in trigram_probabilities:\n",
    "            for word in trigram_probabilities[condition]:\n",
    "                print(f\"Probability of '{word}' given the condition {condition}:{trigram_probabilities[condition][word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0617b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'sit' given the condition ('Can', 'I'):1.0\n",
      "Probability of 'near' given the condition ('I', 'sit'):1.0\n",
      "Probability of 'you' given the condition ('sit', 'near'):1.0\n",
      "Probability of 'You' given the condition ('near', 'you'):1.0\n",
      "Probability of 'can' given the condition ('you', 'You'):1.0\n",
      "Probability of 'sit' given the condition ('You', 'can'):1.0\n",
      "Probability of 'Sit' given the condition ('can', 'sit'):0.5\n",
      "Probability of 'you' given the condition ('can', 'sit'):0.5\n",
      "Probability of 'near' given the condition ('sit', 'Sit'):1.0\n",
      "Probability of 'him' given the condition ('Sit', 'near'):1.0\n",
      "Probability of 'I' given the condition ('near', 'him'):1.0\n",
      "Probability of 'can' given the condition ('him', 'I'):1.0\n",
      "Probability of 'sit' given the condition ('I', 'can'):1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import trigrams\n",
    "from nltk.probability import ConditionalFreqDist, ConditionalProbDist, MLEProbDist\n",
    "corpus = [\n",
    " \"Can I sit near you\",\n",
    " \"You can sit\",\n",
    " \"Sit near him\",\n",
    " \"I can sit you\"\n",
    "]\n",
    "tokenized_corpus = [nltk.word_tokenize(sentence) for sentence in corpus]\n",
    "trigram_list = list(trigrams(word for sentence in tokenized_corpus for word in sentence))\n",
    "cfd = ConditionalFreqDist()\n",
    "for trigram in trigram_list:\n",
    "    condition = (trigram[0], trigram[1])\n",
    "    cfd[condition][trigram[2]] += 1\n",
    "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
    "trigram_probabilities = {}\n",
    "for condition in cpd.conditions():\n",
    "    trigram_probabilities[condition] = {}\n",
    "    for word in cpd[condition].samples():\n",
    "        trigram_probabilities[condition][word] = cpd[condition].prob(word)\n",
    "for condition in trigram_probabilities:\n",
    "    for word in trigram_probabilities[condition]:\n",
    "        print(f\"Probability of '{word}' given the condition {condition}:{trigram_probabilities[condition][word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1a6d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: quote and patient\n",
      "N-grams: ['quo', 'uot', 'ote'] & ['pat', 'ati', 'tie', 'ien', 'ent']\n",
      "Similarity: 0.0000\n",
      "\n",
      "Words: quote and patent\n",
      "N-grams: ['quo', 'uot', 'ote'] & ['pat', 'ate', 'ten', 'ent']\n",
      "Similarity: 0.0000\n",
      "\n",
      "Words: quote and impatient\n",
      "N-grams: ['quo', 'uot', 'ote'] & ['imp', 'mpa', 'pat', 'ati', 'tie', 'ien', 'ent']\n",
      "Similarity: 0.0000\n",
      "\n",
      "Words: patient and patent\n",
      "N-grams: ['pat', 'ati', 'tie', 'ien', 'ent'] & ['pat', 'ate', 'ten', 'ent']\n",
      "Similarity: 0.2857\n",
      "\n",
      "Words: patient and impatient\n",
      "N-grams: ['pat', 'ati', 'tie', 'ien', 'ent'] & ['imp', 'mpa', 'pat', 'ati', 'tie', 'ien', 'ent']\n",
      "Similarity: 0.7143\n",
      "\n",
      "Words: patent and impatient\n",
      "N-grams: ['pat', 'ate', 'ten', 'ent'] & ['imp', 'mpa', 'pat', 'ati', 'tie', 'ien', 'ent']\n",
      "Similarity: 0.2222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "words = [\"quote\", \"patient\", \"patent\", \"impatient\"]\n",
    "n = 3 # Change this value to adjust the n-gram size\n",
    "def generate_ngrams(word):\n",
    "    return [word[i:i+n] for i in range(len(word)-n+1)]\n",
    "word_ngrams = {word: generate_ngrams(word) for word in words}\n",
    "def jaccard_similarity(ngram1, ngram2):\n",
    "    intersection = len(set(ngram1) & set(ngram2))\n",
    "    union = len(set(ngram1) | set(ngram2))\n",
    "    return intersection / union if union else 0\n",
    "# Calculate similarity between each pair of words\n",
    "similarities = { }\n",
    "for i in range(len(words)):\n",
    "    for j in range(i+1, len(words)):\n",
    "        word1, word2 = words[i], words[j]\n",
    "        ngram1, ngram2 = word_ngrams[word1], word_ngrams[word2]\n",
    "        similarities[(word1, word2)] = jaccard_similarity(ngram1, ngram2)\n",
    "# Print the n-grams and their similarities\n",
    "for word1, word2 in similarities:\n",
    "    print(f\"Words: {word1} and {word2}\")\n",
    "    print(f\"N-grams: {word_ngrams[word1]} & {word_ngrams[word2]}\")\n",
    "    print(f\"Similarity: {similarities[(word1, word2)]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90bdeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- qotient: 0.0000\n",
      "- quotent: 0.0000\n",
      "- quotient: 0.0000\n",
      "\n",
      "Most Likely Correct Spelling:\n",
      "qotient\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Define corpus text (a large sample of text)\n",
    "corpus_text = nltk.corpus.gutenberg.raw(\"C:/Users/Public/Gskd/gskd.txt\")\n",
    "words = [\"qotient\", \"quotent\", \"quotient\"] # Include all potential spellings\n",
    "tokens = nltk.word_tokenize(corpus_text.lower())\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "total_words = len(tokens)\n",
    "probabilities = {word: (fdist[word] + 1) / (total_words + len(fdist.keys())) for word in words}\n",
    "for word, prob in probabilities.items():\n",
    "    print(f\"- {word}: {prob:.4f}\")\n",
    "most_likely_word = max(probabilities, key=probabilities.get)\n",
    "print(\"\\nMost Likely Correct Spelling:\")\n",
    "print(most_likely_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223a1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
