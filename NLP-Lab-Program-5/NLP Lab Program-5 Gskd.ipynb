{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7001c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of ('I', 'like'): 0.6666666666666666\n",
      "Probability of ('like', 'pears'): 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "corpus = [\"I like apples\", \"I like bananas\", \"I like oranges\"]\n",
    "sentence = \"I like pears\"\n",
    "corpus_tokens = [nltk.word_tokenize(sentence) for sentence in corpus]\n",
    "sentence_tokens = nltk.word_tokenize(sentence)\n",
    "corpus_ngrams = [ngrams(tokens, 2) for tokens in corpus_tokens]\n",
    "sentence_ngrams = list(ngrams(sentence_tokens, 2))\n",
    "fdist = FreqDist([ngram for ngrams in corpus_ngrams for ngram in ngrams])\n",
    "probabilities = []\n",
    "for ngram in sentence_ngrams:\n",
    "    count = fdist[ngram] + 1 # Add-One smoothing\n",
    "    total_count = len(fdist) + len(sentence_ngrams) # Add-One smoothing\n",
    "    probability = count / total_count\n",
    "    probabilities.append(probability)\n",
    "for ngram, probability in zip(sentence_ngrams, probabilities):\n",
    "    print(f\"Probability of {ngram}: {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb9ad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'John' after 'eos': 0.0000\n",
      "Probability of 'Read' after 'John': 0.0000\n",
      "Probability of 'Fountainhead' after 'Read': 0.3333\n",
      "Probability of 'Mary' after 'Fountainhead': 0.0000\n",
      "Probability of 'a' after 'Mary': 0.0000\n",
      "Probability of 'Different' after 'a': 0.0000\n",
      "Probability of 'Book' after 'Different': 0.0000\n",
      "Probability of 'She' after 'Book': 0.3333\n",
      "Probability of 'By' after 'She': 0.0000\n",
      "Probability of 'Dickens' after 'By': 0.0000\n",
      "Probability of '(eos)' after 'Dickens': 0.3333\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Define bigram counts and smoothing delta\n",
    "bigram_counts = {\n",
    " (\"eos\", \"John\"): 0,\n",
    " (\"John\", \"Read\"): 0,\n",
    " (\"Read\", \"Fountainhead\"): 300,\n",
    " (\"Fountainhead\", \"Mary\"): 0,\n",
    " (\"Mary\", \"a\"): 0,\n",
    " (\"a\", \"Different\"): 0,\n",
    " (\"Different\", \"Book\"): 0,\n",
    " (\"Book\", \"She\"): 300,\n",
    " (\"She\", \"By\"): 0,\n",
    " (\"By\", \"Dickens\"): 0,\n",
    " (\"Dickens\", \"(eos)\"): 300,\n",
    " # Add more bigrams as needed\n",
    "}\n",
    "delta = 0.02 # Smoothing delta value\n",
    "# Calculate total number of bigrams and vocabulary size\n",
    "N = sum(bigram_counts.values())\n",
    "V = len(set(bigram_counts.keys())) # Assuming unique bigrams are keys\n",
    "def add_delta_smoothing(counts, delta, N, V):\n",
    "    smoothed_counts = {ngram: count + delta for ngram, count in counts.items()}\n",
    "    smoothed_probabilities = {ngram: (count + delta) / (N + delta * V) for ngram, count in\n",
    "    smoothed_counts.items()}\n",
    "    return smoothed_probabilities\n",
    "# Apply Add-δ smoothing and print results\n",
    "smoothed_probs = add_delta_smoothing(bigram_counts, delta, N, V)\n",
    "for bigram, prob in smoothed_probs.items():\n",
    "    print(f\"Probability of '{bigram[1]}' after '{bigram[0]}': {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759cb6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) Unsmoothed Probability P(S): 0.0\n",
      "(a) Unsmoothed Probability P(S): 0.0\n",
      "(a) Unsmoothed Probability P(S): 0.0\n",
      "(a) Unsmoothed Probability P(S): 0.0\n",
      "(b) Add-One Smoothing Probability P(S): 0.3333333333333333\n",
      "(b) Add-One Smoothing Probability P(S): 0.1111111111111111\n",
      "(b) Add-One Smoothing Probability P(S): 0.037037037037037035\n",
      "(b) Add-One Smoothing Probability P(S): 0.012345679012345678\n",
      "(c) Add-δ Smoothing Probability P(S): 6.665333599946678e-05\n",
      "(c) Add-δ Smoothing Probability P(S): 4.442667199857814e-09\n",
      "(c) Add-δ Smoothing Probability P(S): 2.9611858960593307e-13\n",
      "(c) Add-δ Smoothing Probability P(S): 1.9737291848692468e-17\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import bigrams\n",
    "from nltk.probability import FreqDist, LidstoneProbDist\n",
    "# Given bigram count table\n",
    "bigram_counts = {\n",
    " ('eos', 'John'): 0,\n",
    " ('eos', 'Read'): 300,\n",
    " # ... (complete the table with the provided counts)\n",
    "}\n",
    "# Sentence to find probability\n",
    "sentence = ['Dickens', 'read', 'a', 'book']\n",
    "# (a) Unsmoothed probability\n",
    "unsmoothed_prob = 1.0\n",
    "for bigram in bigrams(['eos'] + sentence):\n",
    "    unsmoothed_prob *= bigram_counts.get(bigram, 0) / bigram_counts.get((bigram[0],), 1)\n",
    "    print(f\"(a) Unsmoothed Probability P(S): {unsmoothed_prob}\")\n",
    "# (b) Applying Add-One smoothing\n",
    "add_one_prob = 1.0\n",
    "N = sum(bigram_counts.values())\n",
    "V = len(set(word for bigram in bigram_counts.keys() for word in bigram))\n",
    "for bigram in bigrams(['eos'] + sentence):\n",
    "    add_one_prob *= (bigram_counts.get(bigram, 0) + 1) / (bigram_counts.get((bigram[0],), 0) + V)\n",
    "    print(f\"(b) Add-One Smoothing Probability P(S): {add_one_prob}\")\n",
    "# (c) Applying Add-δ smoothing\n",
    "delta = 0.02\n",
    "add_delta_prob = 1.0\n",
    "for bigram in bigrams(['eos'] + sentence):\n",
    "    add_delta_prob *= LidstoneProbDist(FreqDist(bigram_counts), delta, bins=V).prob(bigram)\n",
    "    print(f\"(c) Add-δ Smoothing Probability P(S): {add_delta_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b2611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
