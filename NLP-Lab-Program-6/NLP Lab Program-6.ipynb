{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a1d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov Model Sequence: [0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "Hidden Markov Model Sequence: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovModel:\n",
    "    def __init__(self, transition_matrix, emission_matrix):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.emission_matrix = emission_matrix\n",
    "\n",
    "    def generate_sequence(self, initial_state, length):\n",
    "        current_state = initial_state\n",
    "        sequence = []\n",
    "        for _ in range(length):\n",
    "            sequence.append(current_state)\n",
    "            current_state = np.random.choice(len(self.transition_matrix), p=self.transition_matrix[current_state])\n",
    "        return sequence\n",
    "\n",
    "class HiddenMarkovModel:\n",
    "    def __init__(self, transition_matrix, emission_matrix):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.emission_matrix = emission_matrix\n",
    "\n",
    "    def generate_sequence(self, initial_state, length):\n",
    "        current_state = initial_state\n",
    "        sequence = []\n",
    "        for _ in range(length):\n",
    "            observed_state = np.random.choice(len(self.emission_matrix[current_state]), p=self.emission_matrix[current_state])\n",
    "            sequence.append(observed_state)\n",
    "            current_state = np.random.choice(len(self.transition_matrix), p=self.transition_matrix[current_state])\n",
    "        return sequence\n",
    "\n",
    "# Example usage\n",
    "transition_matrix = np.array([[0.7, 0.3], [0.4, 0.6]])  # Example transition matrix\n",
    "emission_matrix = np.array([[0.9, 0.1], [0.2, 0.8]])  # Example emission matrix\n",
    "\n",
    "# Markov Model\n",
    "markov_model = MarkovModel(transition_matrix, emission_matrix)\n",
    "markov_sequence = markov_model.generate_sequence(initial_state=0, length=10)\n",
    "print(\"Markov Model Sequence:\", markov_sequence)\n",
    "\n",
    "# Hidden Markov Model\n",
    "hidden_markov_model = HiddenMarkovModel(transition_matrix, emission_matrix)\n",
    "hidden_markov_sequence = hidden_markov_model.generate_sequence(initial_state=0, length=10)\n",
    "print(\"Hidden Markov Model Sequence:\", hidden_markov_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abdf7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted POS Tags: ['Noun', 'Adjective', 'Adjective']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM_POS_Tagging:\n",
    "    def __init__(self, states, observations, transition_probabilities, emission_probabilities):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "        self.emission_probabilities = emission_probabilities\n",
    "\n",
    "    def viterbi_algorithm(self, sequence):\n",
    "        T = len(sequence)  # Length of the input sequence\n",
    "        N = len(self.states)  # Number of POS tags\n",
    "\n",
    "        # Initialize dynamic programming table\n",
    "        dp = np.zeros((N, T))\n",
    "        backpointer = np.zeros((N, T), dtype=int)\n",
    "\n",
    "        # Initialize the first column of dp table\n",
    "        for i, state in enumerate(self.states):\n",
    "            dp[i, 0] = self.emission_probabilities[state].get(sequence[0], 0) * 1  # Initial probability * transition probability\n",
    "\n",
    "        # Fill in the dp table\n",
    "        for t in range(1, T):\n",
    "            for i, state in enumerate(self.states):\n",
    "                max_prob = 0\n",
    "                max_index = 0\n",
    "                for j, prev_state in enumerate(self.states):\n",
    "                    prob = dp[j, t-1] * self.transition_probabilities[prev_state].get(state, 0) * self.emission_probabilities[state].get(sequence[t], 0)\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        max_index = j\n",
    "                dp[i, t] = max_prob\n",
    "                backpointer[i, t] = max_index\n",
    "\n",
    "        # Backtrace to find the best path\n",
    "        best_path = [np.argmax(dp[:, T-1])]\n",
    "        for t in range(T-1, 0, -1):\n",
    "            best_path.insert(0, backpointer[best_path[0], t])\n",
    "\n",
    "        return [self.states[i] for i in best_path]\n",
    "\n",
    "# Example usage\n",
    "states = ['Noun', 'Verb', 'Adjective']\n",
    "observations = ['the', 'cat', 'sat']\n",
    "transition_probabilities = {\n",
    "    'Noun': {'Noun': 0.5, 'Verb': 0.2, 'Adjective': 0.3},\n",
    "    'Verb': {'Noun': 0.3, 'Verb': 0.4, 'Adjective': 0.3},\n",
    "    'Adjective': {'Noun': 0.2, 'Verb': 0.3, 'Adjective': 0.5}\n",
    "}\n",
    "emission_probabilities = {\n",
    "    'Noun': {'the': 0.6, 'cat': 0.2, 'sat': 0.2},\n",
    "    'Verb': {'the': 0.1, 'cat': 0.7, 'sat': 0.2},\n",
    "    'Adjective': {'the': 0.2, 'cat': 0.3, 'sat': 0.5}\n",
    "}\n",
    "\n",
    "hmm = HMM_POS_Tagging(states, observations, transition_probabilities, emission_probabilities)\n",
    "sequence = ['the', 'cat', 'sat']\n",
    "predicted_tags = hmm.viterbi_algorithm(sequence)\n",
    "print(\"Predicted POS Tags:\", predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e531806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best path (POS tags): [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM_POS_Tagging:\n",
    "    def __init__(self, transition_matrix, emission_matrix, initial_probabilities):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.emission_matrix = emission_matrix\n",
    "        self.initial_probabilities = initial_probabilities\n",
    "\n",
    "    def viterbi_decode(self, sequence):\n",
    "        T = len(sequence)\n",
    "        N = len(self.transition_matrix)\n",
    "\n",
    "        # Initialize Viterbi matrix and backpointers\n",
    "        V = np.zeros((N, T))\n",
    "        backpointers = np.zeros((N, T), dtype=int)\n",
    "\n",
    "        # Initialize Viterbi matrix with initial probabilities\n",
    "        V[:, 0] = self.initial_probabilities * self.emission_matrix[:, sequence[0]]\n",
    "\n",
    "        # Iterate over each word in the sequence\n",
    "        for t in range(1, T):\n",
    "            for s in range(N):\n",
    "                # Calculate the probability of the best path to state s at time t\n",
    "                V[s, t] = np.max(V[:, t - 1] * self.transition_matrix[:, s]) * self.emission_matrix[s, sequence[t]]\n",
    "                # Store the index of the previous state in the best path\n",
    "                backpointers[s, t] = np.argmax(V[:, t - 1] * self.transition_matrix[:, s])\n",
    "\n",
    "        # Backtrack to find the best path\n",
    "        best_path = [np.argmax(V[:, T - 1])]\n",
    "        for t in range(T - 1, 0, -1):\n",
    "            best_path.append(backpointers[best_path[-1], t])\n",
    "        best_path.reverse()\n",
    "\n",
    "        return best_path\n",
    "\n",
    "# Example usage\n",
    "transition_matrix = np.array([[0.7, 0.3], [0.4, 0.6]])  # Example transition matrix\n",
    "emission_matrix = np.array([[0.9, 0.1], [0.2, 0.8]])  # Example emission matrix\n",
    "initial_probabilities = np.array([0.5, 0.5])  # Example initial probabilities\n",
    "\n",
    "hmm_pos_tagger = HMM_POS_Tagging(transition_matrix, emission_matrix, initial_probabilities)\n",
    "sequence = [0, 1]  # Example sequence of word indices (e.g., [0, 1] corresponds to ['the', 'cat'])\n",
    "\n",
    "best_path = hmm_pos_tagger.viterbi_decode(sequence)\n",
    "print(\"Best path (POS tags):\", best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5849a7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probabilities:\n",
      "VERB: {'ADP': 0.3333333333333333, 'VERB': 0.3333333333333333, 'DET': 0.3333333333333333}\n",
      "DET: {'ADJ': 0.6, 'NOUN': 0.4}\n",
      "ADJ: {'ADJ': 0.25, 'NOUN': 0.75}\n",
      "ADP: {'DET': 1.0}\n",
      "NOUN: {'VERB': 1.0}\n",
      "\n",
      "Emission Probabilities:\n",
      "VERB: {'jumps': 0.25, 'is': 0.25, 'sleeping': 0.25, 'chases': 0.25}\n",
      "DET: {'The': 0.6, 'the': 0.4}\n",
      "ADJ: {'quick': 0.25, 'brown': 0.25, 'lazy': 0.5}\n",
      "ADP: {'over': 1.0}\n",
      "NOUN: {'fox': 0.2, 'dog': 0.4, 'cat': 0.2, 'mouse': 0.2}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class HMM_POS:\n",
    "    def __init__(self, states, transition_probs, emission_probs):\n",
    "        self.states = states\n",
    "        self.transition_probs = transition_probs\n",
    "        self.emission_probs = emission_probs\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # Count occurrences of state transitions and emissions in the corpus\n",
    "        transition_counts = {state: Counter() for state in self.states}\n",
    "        emission_counts = {state: Counter() for state in self.states}\n",
    "\n",
    "        for sentence in corpus:\n",
    "            previous_state = None\n",
    "            for observation, state in sentence:\n",
    "                if previous_state is not None:\n",
    "                    transition_counts[previous_state][state] += 1\n",
    "                emission_counts[state][observation] += 1\n",
    "                previous_state = state\n",
    "\n",
    "        # Estimate transition and emission probabilities from counts\n",
    "        self.transition_probs = {state: {next_state: count / sum(transition_counts[state].values())\n",
    "                                         for next_state, count in counts.items()}\n",
    "                                  for state, counts in transition_counts.items()}\n",
    "        self.emission_probs = {state: {observation: count / sum(emission_counts[state].values())\n",
    "                                       for observation, count in counts.items()}\n",
    "                                for state, counts in emission_counts.items()}\n",
    "\n",
    "# Example corpus\n",
    "corpus = [\n",
    "    [('The', 'DET'), ('quick', 'ADJ'), ('brown', 'ADJ'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN')],\n",
    "    [('The', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('is', 'VERB'), ('sleeping', 'VERB')],\n",
    "    [('The', 'DET'), ('cat', 'NOUN'), ('chases', 'VERB'), ('the', 'DET'), ('mouse', 'NOUN')]\n",
    "]\n",
    "\n",
    "# Initialize HMM\n",
    "states = {'DET', 'NOUN', 'ADJ', 'VERB', 'ADP'}\n",
    "transition_probs = {state: {next_state: 0.2 for next_state in states} for state in states}\n",
    "emission_probs = {state: {'word': 0.2 for word in ['word']} for state in states}\n",
    "\n",
    "hmm = HMM_POS(states, transition_probs, emission_probs)\n",
    "\n",
    "# Train HMM on corpus\n",
    "hmm.train(corpus)\n",
    "\n",
    "# Print transition and emission probabilities\n",
    "print(\"Transition Probabilities:\")\n",
    "for state, probs in hmm.transition_probs.items():\n",
    "    print(f\"{state}: {probs}\")\n",
    "\n",
    "print(\"\\nEmission Probabilities:\")\n",
    "for state, probs in hmm.emission_probs.items():\n",
    "    print(f\"{state}: {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720152f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
