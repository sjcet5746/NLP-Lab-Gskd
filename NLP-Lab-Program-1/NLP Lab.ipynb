{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7abc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d80c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular form: día, lemma: día, features: {'Gender': 'masculine', 'Number': 'singular'}\n",
      "Plural form: días, lemma: días, features: {'Gender': 'masculine', 'Number': 'plural'}\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "spanish_lemmatizer = nltk.stem.WordNetLemmatizer() \n",
    "# Singular forms \n",
    "dia = \"día\"\n",
    "dia_lemma = spanish_lemmatizer.lemmatize(dia, \"n\") \n",
    "dia_plural = \"días\" \n",
    "dia_plural_lemma = spanish_lemmatizer.lemmatize(dia_plural, \"n\") \n",
    " \n",
    "# Gender \n",
    "gender = \"masculine\" \n",
    " \n",
    "# Number \n",
    "number = \"singular\" \n",
    "number_plural = \"plural\" \n",
    " \n",
    "# Part of speech \n",
    "pos = \"noun\" \n",
    " \n",
    "# Syntactic features \n",
    "features = { \n",
    "    \"Gender\": gender, \n",
    "    \"Number\": number \n",
    "} \n",
    "features_plural = { \n",
    "    \"Gender\": gender, \n",
    "    \"Number\": number_plural \n",
    "}\n",
    "# Print results \n",
    "print(f\"Singular form: {dia}, lemma: {dia_lemma}, features: {features}\") \n",
    "print(f\"Plural form: {dia_plural}, lemma: {dia_plural_lemma}, features: {features_plural}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd244552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Red', 'JJ'), ('Mad', 'NNP'), ('Soft', 'NNP'), ('Wide', 'NNP'), ('Sharp', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "list_a = ['Red', 'Mad', 'Soft', 'Wide', 'Sharp'] \n",
    "tagged_list_a = nltk.pos_tag(list_a) \n",
    "print(tagged_list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e4d798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: madden\n",
      "Lemma: madden\n",
      "Suffix: \n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wnl = WordNetLemmatizer() \n",
    "word = 'madden' \n",
    "lemma = wnl.lemmatize(word, 'v') \n",
    "print(f\"Word: {word}\") \n",
    "print(f\"Lemma: {lemma}\") \n",
    "print(f\"Suffix: {word[len(lemma):]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e344cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past_perfect_continuous Third_plural: had been runing (they)\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    " \n",
    "# Initialize the WordNetLemmatizer \n",
    "wnl = WordNetLemmatizer() \n",
    " \n",
    "# Define the verb \n",
    "verb = \"run\" \n",
    " \n",
    "# Define the tenses and aspects \n",
    "tenses_aspects = [\"infinitive\", \"present\", \"past\", \"present_continuous\", \"past_continuous\", \"present_perfect\", \"past_perfect\", \"present_perfect_continuous\", \"past_perfect_continuous\"] \n",
    " \n",
    "# Define the persons \n",
    "persons = [\"first_singular\", \"second_singular\", \"third_singular\", \"first_plural\", \"second_plural\", \"third_plural\"] \n",
    " \n",
    "# Loop through all combinations and print the result \n",
    "for tense_aspect in tenses_aspects: \n",
    "    for person in persons: \n",
    "        if tense_aspect == \"infinitive\": \n",
    "            if person == \"third_singular\": \n",
    "                result = wnl.lemmatize(verb, \"v\") \n",
    "            else: \n",
    "                result = verb \n",
    "        elif tense_aspect == \"present\": \n",
    "            if person == \"third_singular\": \n",
    "                result = verb + \"s\" \n",
    "            else: \n",
    "                result = verb \n",
    "        elif tense_aspect == \"past\": \n",
    "            if verb[-1] == \"e\": \n",
    "                result = verb + \"d\" \n",
    "            elif verb[-2:] == \"y\": \n",
    "                result = verb[:-1] + \"ied\" \n",
    "            else: \n",
    "                result = verb + \"ed\" \n",
    "        elif tense_aspect == \"present_continuous\": \n",
    "            result = \"am/is/are \" + verb + \"ing\" \n",
    "        elif tense_aspect == \"past_continuous\": \n",
    "            result = \"was/were \" + verb + \"ing\" \n",
    "        elif tense_aspect == \"present_perfect\": \n",
    "            result = \"have/has \" + verb + \"ed\" \n",
    "        elif tense_aspect == \"past_perfect\": \n",
    "            result = \"had \" + verb + \"ed\" \n",
    "        elif tense_aspect == \"present_perfect_continuous\": \n",
    "            result = \"have/has been \" + verb + \"ing\" \n",
    "        elif tense_aspect == \"past_perfect_continuous\": \n",
    "            result = \"had been \" + verb + \"ing\" \n",
    " \n",
    "        # Add the person to the result \n",
    "    if person == \"first_singular\": \n",
    "        result += \" (I)\" \n",
    "    elif person == \"second_singular\": \n",
    "        result += \" (you)\" \n",
    "    elif person == \"third_singular\": \n",
    "        result += \" (he/she/it)\" \n",
    "    elif person == \"first_plural\": \n",
    "        result += \" (we)\" \n",
    "    elif person == \"second_plural\": \n",
    "        result += \" (you all)\" \n",
    "    elif person == \"third_plural\": \n",
    "        result += \" (they)\" \n",
    "        \n",
    "        # Print the result \n",
    "print(tense_aspect.capitalize() + \" \" + person.capitalize() + \": \" + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33b5c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words ending with 'er'/'or' do not have a common feature.\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    " \n",
    "# Define the three lists of words \n",
    "list1 = ['taller', 'shorter', 'higher', 'lower', 'smarter'] \n",
    "list2 = ['mower', 'teacher', 'sailor', 'caller', 'operator'] \n",
    "list3 = ['never', 'cover', 'finger', 'river'] \n",
    " \n",
    "# Use the NLTK POS tagger to get the POS tags of the words \n",
    "pos_tags_list1 = nltk.pos_tag(list1) \n",
    "pos_tags_list2 = nltk.pos_tag(list2) \n",
    "pos_tags_list3 = nltk.pos_tag(list3) \n",
    " \n",
    "# Filter out the words that end with 'er' or 'or' \n",
    "er_words = [word for word, pos in pos_tags_list1 if word[-2:] == 'er'] \n",
    "or_words = [word for word, pos in pos_tags_list2 if word[-2:] == 'or'] \n",
    " \n",
    "# Check if the filtered words have a common POS tag \n",
    "er_pos_tags = set(pos for word, pos in pos_tags_list1 if word[-2:] == 'er') \n",
    "or_pos_tags = set(pos for word, pos in pos_tags_list2 if word[-2:] == 'or') \n",
    " \n",
    "if len(er_pos_tags) == 1 and len(or_pos_tags) == 1 and er_pos_tags == or_pos_tags: \n",
    "    print(\"The words ending with 'er'/'or' have a common feature of indicating the agent or doer of an action or the one who performs a specific role or function.\") \n",
    "else: \n",
    "    print(\"The words ending with 'er'/'or' do not have a common feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06bfffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kissed: root='kiss', suffix='ed'\n",
      "stronger: root='stronger', suffix=''\n",
      "goodness: root='good', suffix='ness'\n",
      "teacher: root='teacher', suffix=''\n",
      "achievement: root='achiev', suffix='ement'\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import SnowballStemmer \n",
    " \n",
    "# Create a Snowball stemmer for English \n",
    "stemmer = SnowballStemmer('english') \n",
    " \n",
    "# Define the list of words \n",
    "words = ['kissed', 'stronger', 'goodness', 'teacher', 'achievement'] \n",
    " \n",
    "# Iterate over the words and identify their root and suffix \n",
    "for word in words: \n",
    "    root = stemmer.stem(word) \n",
    "    suffix = word[len(root):] \n",
    "    print(f\"{word}: root='{root}', suffix='{suffix}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d14a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
