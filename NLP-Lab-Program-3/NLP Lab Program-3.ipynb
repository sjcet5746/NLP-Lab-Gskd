{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91dc7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in paradigm with pattern \"मनुष्य\": मनुष्य\n",
      "Words in paradigm with pattern \"पक्षी\": पक्षी\n",
      "Words in paradigm with pattern \"शिशु\": शिशु\n",
      "Words in paradigm with pattern \"गुरु\": गुरु\n",
      "Words in paradigm with pattern \"नर\": नर\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Define the list of words\n",
    "words = ['मनुष्य', 'पक्षी', 'शिशु', 'गुरु', 'नर']\n",
    "\n",
    "# Define the morphological patterns for the paradigm\n",
    "paradigm_pattern = r'(.*?)$'\n",
    "\n",
    "# Create an empty dictionary to store the paradigm groups\n",
    "paradigm_groups = {}\n",
    "\t\n",
    "# Iterate through each word\n",
    "for word in words:\n",
    "    # Extract the morphological pattern of the word\n",
    "    morphological_pattern = nltk.regexp_tokenize(word, paradigm_pattern)[0]\n",
    "\n",
    "    # If the pattern is not in the paradigm groups dictionary, add it with the current word as the value\n",
    "    if morphological_pattern not in paradigm_groups:\n",
    "        paradigm_groups[morphological_pattern] = [word]\n",
    "    else:\n",
    "        # If the pattern is already in the paradigm groups dictionary, append the current word to the existing value\n",
    "        paradigm_groups[morphological_pattern].append(word)\n",
    "\n",
    "# Print the paradigm groups\n",
    "for pattern, group in paradigm_groups.items():\n",
    "    print(f'Words in paradigm with pattern \"{pattern}\": {\", \".join(group)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96bb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paradigm table for मनुष्य:\n",
      "| Person   | Gender   | Number   | Inflected Word   |\n",
      "|:---------|:---------|:---------|:-----------------|\n",
      "| 3p       | Neut     | Pl       | वे Neut Pl        |\n",
      "Paradigm table for पक्षी:\n",
      "| Person   | Gender   | Number   | Inflected Word   |\n",
      "|:---------|:---------|:---------|:-----------------|\n",
      "| 3p       | Neut     | Pl       | वे Neut Pl        |\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m             inflected_word \u001b[38;5;241m=\u001b[39m inflections[word][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson\u001b[39m\u001b[38;5;124m\"\u001b[39m][categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(person)]\n\u001b[0;32m     49\u001b[0m         inflected_word \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39minflections[word][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m\"\u001b[39m][categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(gender)]\n\u001b[1;32m---> 50\u001b[0m     inflected_word \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m inflections[word][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m][categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(number)]\n\u001b[0;32m     51\u001b[0m table\u001b[38;5;241m.\u001b[39mappend((person, gender, number, inflected_word))\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParadigm table for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "# Define the words\n",
    "words = [\"मनुष्य\", \"पक्षी\", \"शिशु\", \"गुरु\", \"नर\"]\n",
    " \n",
    "# Define the morphological categories\n",
    "categories = {\n",
    "    \"Person\": [\"1s\", \"2s\", \"3s\", \"1p\", \"2p\", \"3p\"],\n",
    "    \"Gender\": [\"Masc\", \"Fem\", \"Neut\"],\n",
    "    \"Number\": [\"Sg\", \"Pl\"]\n",
    "}\n",
    "# Define the inflection rules for each word\n",
    "inflections = {\n",
    "    \"मनुष्य\": {\n",
    "        \"Person\": [\"मैं\", \"तुम\", \"वह\", \"हम\", \"तुम्हारे\", \"वे\"],\n",
    "        \"Gender\": [\"Masc\", \"Fem\", \"Neut\"],\n",
    "        \"Number\": [\"Sg\", \"Pl\"]\n",
    "    },\n",
    "    \"पक्षी\": {\n",
    "        \"Person\": [\"मैं\", \"तुम\", \"वह\", \"हम\", \"तुम्हारे\", \"वे\"],\n",
    "        \"Gender\": [\"Masc\", \"Fem\", \"Neut\"],\n",
    "        \"Number\": [\"Sg\", \"Pl\"]\n",
    "    },\n",
    "    \"शिशु\": {\n",
    "        \"Person\": [\"मैं\", \"तुम\", \"वह\", \"हम\", \"तुम्हारे\", \"वे\"],\n",
    "        \"Gender\": [\"Masc\", \"Fem\", \"Neut\"],\n",
    "        \"Number\": [\"Sg\"]\n",
    "    },\n",
    "    \"गुरु\": {\n",
    "        \"Person\": [\"मैं\", \"तुम\", \"वह\", \"हम\", \"तुम्हारे\", \"वे\"],\n",
    "        \"Gender\": [\"Masc\"],\n",
    "        \"Number\": [\"Sg\"]\n",
    "    },\n",
    "    \"नर\": {\n",
    "        \"Person\": [\"मैं\", \"तुम\", \"वह\", \"हम\", \"तुम्हारे\", \"वे\"],\n",
    "        \"Gender\": [\"Masc\"],\n",
    "        \"Number\": [\"Sg\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Construct the paradigm table for each word\n",
    "from tabulate import tabulate\n",
    "for word in words:\n",
    "    table = []\n",
    "    for person in categories[\"Person\"]:\n",
    "        for gender in categories[\"Gender\"]:\n",
    "            for number in categories[\"Number\"]:\n",
    "                inflected_word = inflections[word][\"Person\"][categories[\"Person\"].index(person)]\n",
    "            inflected_word += \" \" +inflections[word][\"Gender\"][categories[\"Gender\"].index(gender)]\n",
    "        inflected_word += \" \" + inflections[word][\"Number\"][categories[\"Number\"].index(number)]\n",
    "    table.append((person, gender, number, inflected_word))\n",
    "    print(f\"Paradigm table for {word}:\")\n",
    "    print(tabulate(table, headers=[\"Person\", \"Gender\", \"Number\", \"Inflected Word\"], tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be08ed54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not identify morphemes for kori\n",
      "Could not identify morphemes for maari\n",
      "Could not identify morphemes for korchille\n",
      "Could not identify morphemes for maar\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMorphemes for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m morpheme, meaning \u001b[38;5;129;01min\u001b[39;00m morpheme_list:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmorpheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeaning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "# Define the words\n",
    "words = [\"kori\", \"maari\", \"korchille\", \"maar\"]\n",
    "\n",
    "# Define the morpheme boundaries and their meanings\n",
    "morphemes = {\n",
    "    \"ko\": \"1s Subject Pronoun\",\n",
    "    \"ri\": \"Do Verb Stem\",\n",
    "    \"ma\": \"1s Subject Pronoun\",\n",
    "    \"ar\": \"Hit Verb Stem\",\n",
    "    \"chille\": \"2s Past Tense Auxiliary Verb\",\n",
    "}\n",
    "\n",
    "# Define a function to split a word into its morphemes\n",
    "def split_word(word):\n",
    "    morpheme_list = []\n",
    "    while len(word) > 0:\n",
    "        for morpheme, meaning in morphemes.items():\n",
    "            if word.endswith(morpheme):\n",
    "                morpheme_list.append((morpheme, meaning))\n",
    "                word = word[:len(word)-len(morpheme)]\n",
    "                break\n",
    "            else:\n",
    "            # No morpheme found\n",
    "                return None\n",
    "    morpheme_list.reverse()\n",
    "    return morpheme_list\n",
    "\n",
    "# Identify the morphemes and their meanings for each word\n",
    "for word in words:\n",
    "    morpheme_list = split_word(word)\n",
    "    if morpheme_list is None:\n",
    "        print(f\"Could not identify morphemes for {word}\")\n",
    "    else:\n",
    "        print(f\"Morphemes for {word}:\")\n",
    "for morpheme, meaning in morpheme_list:\n",
    "    print(f\"{morpheme}: {meaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994cd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paradigm: मनुष\n",
      "Words belonging to the same paradigm: ['मनुष्य']\n",
      "Paradigm: पक्\n",
      "Words belonging to the same paradigm: ['पक्षी']\n",
      "Paradigm: शि\n",
      "Words belonging to the same paradigm: ['शिशु']\n",
      "Paradigm: गु\n",
      "Words belonging to the same paradigm: ['गुरु']\n",
      "Paradigm: \n",
      "Words belonging to the same paradigm: ['नर']\n"
     ]
    }
   ],
   "source": [
    "class HindiWord:\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "\n",
    "    def get_features(self):\n",
    "        features = {\n",
    "            'root': self.word[:-2],\n",
    "            'ending': self.word[-2:]\n",
    "        }\n",
    "        return features\n",
    "\n",
    "def select_same_paradigm_words(words):\n",
    "    paradigms = {}\n",
    "    for word in words:\n",
    "        word_obj = HindiWord(word)\n",
    "        features = word_obj.get_features()\n",
    "        root = features['root']\n",
    "        if root not in paradigms:\n",
    "            paradigms[root] = []\n",
    "        paradigms[root].append(word)\n",
    "\n",
    "    return paradigms\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    words = ['मनुष्य', 'पक्षी', 'शिशु', 'गुरु', 'नर']\n",
    "    paradigms = select_same_paradigm_words(words)\n",
    "    for root, paradigm_words in paradigms.items():\n",
    "        print(\"Paradigm:\", root)\n",
    "        print(\"Words belonging to the same paradigm:\", paradigm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232c67ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paradigm Table:\n",
      "Root       Gender     Number     Case      \n",
      "मनुष्य     masculine  singular   direct    \n",
      "मनुष्य     masculine  plural     direct    \n",
      "\n",
      "पक्षी      masculine  singular   direct    \n",
      "पक्षी      masculine  plural     direct    \n",
      "\n",
      "शिशु       neuter     singular   direct    \n",
      "शिशु       neuter     plural     direct    \n",
      "\n",
      "गुरु       masculine  singular   direct    \n",
      "गुरु       masculine  plural     direct    \n",
      "\n",
      "नर         masculine  singular   direct    \n",
      "नर         masculine  plural     direct    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class HindiWord:\n",
    "    def __init__(self, root, gender, number, case):\n",
    "        self.root = root\n",
    "        self.gender = gender\n",
    "        self.number = number\n",
    "        self.case = case\n",
    "\n",
    "    def generate_word(self):\n",
    "        if self.number == 'singular':\n",
    "            if self.gender == 'masculine':\n",
    "                if self.case == 'direct':\n",
    "                    return self.root\n",
    "                elif self.case == 'oblique':\n",
    "                    return self.root[:-1] + 'e'\n",
    "            elif self.gender == 'feminine':\n",
    "                if self.case == 'direct':\n",
    "                    return self.root\n",
    "                elif self.case == 'oblique':\n",
    "                    return self.root[:-1] + 'e'\n",
    "            elif self.gender == 'neuter':\n",
    "                if self.case == 'direct':\n",
    "                    return self.root\n",
    "                elif self.case == 'oblique':\n",
    "                    return self.root[:-1] + 'e'\n",
    "        elif self.number == 'plural':\n",
    "            if self.gender == 'masculine' or self.gender == 'feminine':\n",
    "                return self.root[:-1] + 'e'\n",
    "\n",
    "# Grouping the words based on their grammatical features\n",
    "words = [\n",
    "    HindiWord('मनुष्य', 'masculine', 'singular', 'direct'),\n",
    "    HindiWord('पक्षी', 'masculine', 'singular', 'direct'),\n",
    "    HindiWord('शिशु', 'neuter', 'singular', 'direct'),\n",
    "    HindiWord('गुरु', 'masculine', 'singular', 'direct'),\n",
    "    HindiWord('नर', 'masculine', 'singular', 'direct')\n",
    "]\n",
    "\n",
    "# Generate the paradigm table\n",
    "print(\"Paradigm Table:\")\n",
    "print(\"{:<10} {:<10} {:<10} {:<10}\".format(\"Root\", \"Gender\", \"Number\", \"Case\"))\n",
    "for word in words:\n",
    "    generated_word = word.generate_word()\n",
    "    print(\"{:<10} {:<10} {:<10} {:<10}\".format(word.root, word.gender, word.number, word.case))\n",
    "    print(\"{:<10} {:<10} {:<10} {:<10}\".format(generated_word, word.gender, \"plural\", word.case))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "331bc785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: kori\n",
      "Morphemes:\n",
      "ko - (I)\n",
      "ri - do\n",
      "\n",
      "Word: maari\n",
      "Morphemes:\n",
      "ma - (I)\n",
      "ari - hit\n",
      "\n",
      "Word: korchille\n",
      "Morphemes:\n",
      "kor - (You)\n",
      "chil - were\n",
      "le - doing\n",
      "\n",
      "Word: maar\n",
      "Morphemes:\n",
      "ma - (You)\n",
      "ar - hit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class BengaliWord:\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "\n",
    "    def identify_morphemes(self):\n",
    "        morphemes = {\n",
    "            'kori': [('ko', '(I)'), ('ri', 'do')],\n",
    "            'maari': [('ma', '(I)'), ('ari', 'hit')],\n",
    "            'korchille': [('kor', '(You)'), ('chil', 'were'), ('le', 'doing')],\n",
    "            'maar': [('ma', '(You)'), ('ar', 'hit')]\n",
    "        }\n",
    "\n",
    "        if self.word in morphemes:\n",
    "            print(f\"Word: {self.word}\")\n",
    "            print(\"Morphemes:\")\n",
    "            for morpheme, meaning in morphemes[self.word]:\n",
    "                print(f\"{morpheme} - {meaning}\")\n",
    "        else:\n",
    "            print(\"Word not found in the dictionary.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    bengali_words = ['kori', 'maari', 'korchille', 'maar']\n",
    "    for word in bengali_words:\n",
    "        analyzer = BengaliWord(word)\n",
    "        analyzer.identify_morphemes()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8265bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
